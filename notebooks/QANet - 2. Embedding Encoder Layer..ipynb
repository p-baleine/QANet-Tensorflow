{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "position encoding + [convolution-layer × # + self-attention-layer + feed-forward-layer]\n",
    "\n",
    "> We use depthwise separable convolutions (Chollet, 2016) (Kaiser et al., 2017) rather than traditional ones, as we observe that it is memory efficient and has better generalization.\n",
    "\n",
    "これはkerasが持ってくれている - [SeparableConv2D](https://keras.io/layers/convolutional/#separableconv2d)\n",
    "\n",
    "> For the self-attention-layer, we adopt the multi-head attention mechanism\n",
    "\n",
    "これは自前実装が必要そう\n",
    "\n",
    "勉強だから自分で実装するけど、答えは[ここ](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/layers/common_attention.py#L2557)\n",
    "\n",
    "> A positional encoding is added to the input at the beginning of each encoder layer consisting of sin and cos functions at varying wavelengths, as defined in (Vaswani et al., 2017a). \n",
    "\n",
    "これも自前かな？元論文にあたる\n",
    "\n",
    "tensor2tensorに[実装](https://github.com/tensorflow/tensor2tensor/blob/ed9e3bdfd0292d4b6e5b1a1bf272146c8e2f5e9f/tensor2tensor/layers/common_attention.py#L386)がある。これ使わせてもらいたいなぁ\n",
    "\n",
    "tensor2tensor自体をpip installしてimportできちゃった、超横着\n",
    "\n",
    "(これやりだすとmulti-head attentionだってimportできちゃうんじゃないのか？勉強したいから自分で書くつもりだけど…)\n",
    "\n",
    "> Each of these basic operations (conv/self-attention/ffn) is placed inside a residual block\n",
    "\n",
    "これも自前かな？\n",
    "\n",
    "ドロップアウト系は後で見直しが必要だな\n",
    "\n",
    "layernormとかresidual networkとかはtransformerでもやっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensor2tensor.layers.common_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2tensor.layers.common_attention.get_timing_signal_1d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled Dot-Product Attention\n",
    "\n",
    "d_k = 20\n",
    "d_v = 24\n",
    "n = 5\n",
    "batch_size = 2\n",
    "\n",
    "def dot_product_attention(Q, K, V):\n",
    "    d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "    return tf.matmul(tf.nn.softmax(\n",
    "        tf.matmul(Q, K, transpose_b=True) / tf.square(d_k)), V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=22, shape=(2, 5, 24), dtype=float32, numpy=\n",
       "array([[[-0.2755355 ,  0.02543714, -0.6558655 , -0.39848557,\n",
       "          0.08035114, -0.21854311, -0.06740077,  0.31412017,\n",
       "          0.00938186,  0.12228555, -0.8029323 ,  0.4190522 ,\n",
       "         -0.01590724, -0.4729288 , -0.2317182 , -0.1456897 ,\n",
       "          0.25555655,  0.16826384, -0.43338117,  0.03029106,\n",
       "         -0.3693037 , -0.5143404 ,  0.60283834, -0.08868167],\n",
       "        [-0.2725145 ,  0.01626787, -0.6460343 , -0.41061652,\n",
       "          0.077563  , -0.2134846 , -0.05939922,  0.32173946,\n",
       "          0.023509  ,  0.12638085, -0.8015075 ,  0.43884793,\n",
       "         -0.01859665, -0.46918342, -0.22741178, -0.15097655,\n",
       "          0.2623397 ,  0.17699657, -0.45197996,  0.02225801,\n",
       "         -0.36940283, -0.50536317,  0.5990656 , -0.0851727 ],\n",
       "        [-0.277115  ,  0.01595478, -0.6528961 , -0.40403602,\n",
       "          0.07815958, -0.21463348, -0.06500801,  0.31738865,\n",
       "          0.01783026,  0.12823199, -0.80387074,  0.4270888 ,\n",
       "         -0.01027798, -0.4738617 , -0.2304362 , -0.14762428,\n",
       "          0.2604715 ,  0.17735437, -0.44341862,  0.02406358,\n",
       "         -0.36958352, -0.5087473 ,  0.60321003, -0.08684012],\n",
       "        [-0.27206466,  0.0168616 , -0.64624715, -0.41015574,\n",
       "          0.07730508, -0.21079893, -0.06214756,  0.3191995 ,\n",
       "          0.02451946,  0.12512976, -0.80138355,  0.44174695,\n",
       "         -0.02133534, -0.46754453, -0.22294061, -0.1522717 ,\n",
       "          0.2620042 ,  0.17907241, -0.45146087,  0.02381011,\n",
       "         -0.3681135 , -0.5048171 ,  0.5990797 , -0.0851174 ],\n",
       "        [-0.27451572,  0.02441156, -0.66017616, -0.40434673,\n",
       "          0.08256938, -0.21724106, -0.06167634,  0.31788135,\n",
       "          0.00652959,  0.1318337 , -0.79757667,  0.42155135,\n",
       "         -0.01517726, -0.47214118, -0.23771708, -0.1463226 ,\n",
       "          0.2639143 ,  0.17153151, -0.44081447,  0.02695699,\n",
       "         -0.36781442, -0.50867236,  0.60406286, -0.08978797]],\n",
       "\n",
       "       [[ 0.73280936, -0.5699864 , -0.23621255, -0.10323515,\n",
       "         -0.03584844, -0.4384019 ,  0.5271573 ,  1.3619022 ,\n",
       "          0.3113628 ,  0.30152327,  0.36282602,  0.11320034,\n",
       "         -0.7870061 , -0.18890505,  0.34390712, -0.929523  ,\n",
       "          0.04939941,  0.17525232, -0.46843925, -0.2538252 ,\n",
       "         -0.62001216,  0.67691094,  0.48515868, -0.19714798],\n",
       "        [ 0.73823404, -0.56872714, -0.2290594 , -0.10281187,\n",
       "         -0.02010803, -0.4289386 ,  0.511586  ,  1.3577398 ,\n",
       "          0.3145872 ,  0.30473205,  0.3668574 ,  0.12067055,\n",
       "         -0.8016642 , -0.20079449,  0.3435179 , -0.91714376,\n",
       "          0.04017325,  0.18123135, -0.47159436, -0.24484174,\n",
       "         -0.61981106,  0.6770009 ,  0.5065605 , -0.20631826],\n",
       "        [ 0.7330966 , -0.5705958 , -0.23404585, -0.09931398,\n",
       "         -0.02384888, -0.43515942,  0.5241285 ,  1.3565512 ,\n",
       "          0.30913255,  0.30649218,  0.36644846,  0.1216635 ,\n",
       "         -0.79517305, -0.19194433,  0.3447498 , -0.921058  ,\n",
       "          0.0476663 ,  0.17944597, -0.46845737, -0.2454636 ,\n",
       "         -0.6168051 ,  0.67191637,  0.493151  , -0.20165464],\n",
       "        [ 0.7340747 , -0.57343674, -0.23029004, -0.09930924,\n",
       "         -0.02100946, -0.43366015,  0.5204761 ,  1.3563447 ,\n",
       "          0.31143895,  0.30645487,  0.3663817 ,  0.12275621,\n",
       "         -0.79766756, -0.1922783 ,  0.34495142, -0.91999143,\n",
       "          0.04500529,  0.1810508 , -0.46941838, -0.24444988,\n",
       "         -0.6159291 ,  0.67121226,  0.4973787 , -0.20477326],\n",
       "        [ 0.7407328 , -0.5758429 , -0.23219138, -0.09943652,\n",
       "         -0.02563856, -0.43362167,  0.513182  ,  1.3587334 ,\n",
       "          0.30883396,  0.3059452 ,  0.36947525,  0.12103911,\n",
       "         -0.7919614 , -0.18996447,  0.3463601 , -0.92414564,\n",
       "          0.04405691,  0.17660345, -0.47203875, -0.25074092,\n",
       "         -0.62149256,  0.6811187 ,  0.48947132, -0.1989482 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "Q = np.random.randn(batch_size, n, d_k).astype(np.float32)\n",
    "K = np.random.randn(batch_size, n, d_k).astype(np.float32)\n",
    "V = np.random.randn(batch_size, n, d_v).astype(np.float32)\n",
    "\n",
    "dot_product_attention(Q, K, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=43, shape=(2, 3, 5, 24), dtype=float32, numpy=\n",
       "array([[[[-4.64355499e-01,  2.69382715e-01, -4.61483561e-02,\n",
       "           1.88717410e-01,  1.37169406e-01, -2.60713875e-01,\n",
       "           8.99664998e-01,  4.32149261e-01,  1.04205871e+00,\n",
       "          -9.48710382e-01,  3.28569591e-01,  1.01595843e+00,\n",
       "           1.54692337e-01,  3.78855169e-01,  7.48895109e-01,\n",
       "           9.90934968e-02, -7.83676803e-01,  1.07098937e+00,\n",
       "           2.24177644e-01, -2.60871798e-01, -2.38526314e-01,\n",
       "          -6.25384003e-02,  4.02206965e-02,  2.06599742e-01],\n",
       "         [-4.51582968e-01,  2.87480295e-01, -8.14244375e-02,\n",
       "           1.72389135e-01,  1.54843479e-01, -2.63549954e-01,\n",
       "           9.22879934e-01,  4.21254009e-01,  1.03930056e+00,\n",
       "          -9.52462614e-01,  3.44345272e-01,  1.03775787e+00,\n",
       "           1.55778974e-01,  4.01335001e-01,  7.56202757e-01,\n",
       "           9.12728831e-02, -8.02596569e-01,  1.07786441e+00,\n",
       "           2.31840387e-01, -2.67707944e-01, -2.39055395e-01,\n",
       "          -4.78027388e-02,  4.32471186e-02,  2.30094016e-01],\n",
       "         [-4.61416483e-01,  2.76290923e-01, -5.83217628e-02,\n",
       "           1.80411175e-01,  1.48279041e-01, -2.61038095e-01,\n",
       "           9.08467174e-01,  4.27837729e-01,  1.03405321e+00,\n",
       "          -9.49578226e-01,  3.34262997e-01,  1.02953410e+00,\n",
       "           1.59854591e-01,  3.83479476e-01,  7.53961623e-01,\n",
       "           9.12001505e-02, -7.91918993e-01,  1.07623720e+00,\n",
       "           2.24947304e-01, -2.56801814e-01, -2.38484353e-01,\n",
       "          -5.96961789e-02,  5.10971844e-02,  2.19825938e-01],\n",
       "         [-4.50782061e-01,  2.88681835e-01, -8.60883221e-02,\n",
       "           1.69484571e-01,  1.60222843e-01, -2.63230681e-01,\n",
       "           9.25241828e-01,  4.20397490e-01,  1.03594720e+00,\n",
       "          -9.52337921e-01,  3.47719550e-01,  1.04279506e+00,\n",
       "           1.57390848e-01,  4.01535809e-01,  7.59354889e-01,\n",
       "           8.86166915e-02, -8.05472076e-01,  1.08005071e+00,\n",
       "           2.32477576e-01, -2.66528666e-01, -2.37071767e-01,\n",
       "          -4.64321896e-02,  4.64857183e-02,  2.35016301e-01],\n",
       "         [-4.50953573e-01,  2.83503830e-01, -8.37789699e-02,\n",
       "           1.77441329e-01,  1.53457418e-01, -2.64088094e-01,\n",
       "           9.21768248e-01,  4.24621582e-01,  1.04619789e+00,\n",
       "          -9.52350795e-01,  3.47776800e-01,  1.03101838e+00,\n",
       "           1.51281580e-01,  4.01160032e-01,  7.55806267e-01,\n",
       "           9.51664522e-02, -8.01659465e-01,  1.07642758e+00,\n",
       "           2.33398974e-01, -2.73089945e-01, -2.33464509e-01,\n",
       "          -4.61465120e-02,  3.25200073e-02,  2.25338206e-01]],\n",
       "\n",
       "        [[-1.43372476e-01,  1.88475713e-01, -1.21482082e-01,\n",
       "           6.34332538e-01,  3.59556794e-01, -6.75043702e-01,\n",
       "           1.62171513e-01, -4.41527098e-01, -9.81306136e-02,\n",
       "          -2.52017349e-01, -3.52814287e-01, -4.39085186e-01,\n",
       "          -3.14857990e-01,  6.82816029e-01, -9.38929543e-02,\n",
       "           5.64331636e-02,  6.09587617e-02, -3.20485502e-01,\n",
       "          -3.01404923e-01, -2.33672172e-01,  2.66877585e-03,\n",
       "          -9.53517184e-02,  2.06164390e-01,  2.25833476e-01],\n",
       "         [-1.41106725e-01,  1.83697253e-01, -1.18255317e-01,\n",
       "           6.43997967e-01,  3.52955520e-01, -6.70101583e-01,\n",
       "           1.62001878e-01, -4.42524105e-01, -1.02336898e-01,\n",
       "          -2.47148201e-01, -3.59990746e-01, -4.40699905e-01,\n",
       "          -3.19129020e-01,  6.88048780e-01, -8.85659158e-02,\n",
       "           6.75529689e-02,  5.32898046e-02, -3.27257365e-01,\n",
       "          -3.02184761e-01, -2.30538249e-01,  4.56046080e-03,\n",
       "          -9.43213627e-02,  2.06801370e-01,  2.20070422e-01],\n",
       "         [-1.37578845e-01,  1.75428286e-01, -1.17551394e-01,\n",
       "           6.36026144e-01,  3.47748041e-01, -6.72650278e-01,\n",
       "           1.71594381e-01, -4.43271369e-01, -9.53735933e-02,\n",
       "          -2.39991784e-01, -3.56246114e-01, -4.58299279e-01,\n",
       "          -3.18944722e-01,  6.92977786e-01, -9.41889435e-02,\n",
       "           6.86175600e-02,  5.76415025e-02, -3.34948659e-01,\n",
       "          -3.01376909e-01, -2.20298499e-01,  3.24542192e-03,\n",
       "          -9.47384462e-02,  2.03630820e-01,  2.20024228e-01],\n",
       "         [-1.41998187e-01,  1.91422284e-01, -1.20343208e-01,\n",
       "           6.36429965e-01,  3.56279403e-01, -6.71851635e-01,\n",
       "           1.61833555e-01, -4.40047890e-01, -9.80756655e-02,\n",
       "          -2.49576390e-01, -3.51708859e-01, -4.36103433e-01,\n",
       "          -3.16518992e-01,  6.83886588e-01, -9.28477347e-02,\n",
       "           5.68595566e-02,  6.07968122e-02, -3.20074797e-01,\n",
       "          -3.01132292e-01, -2.33902603e-01,  2.52954802e-03,\n",
       "          -9.66200903e-02,  2.07901955e-01,  2.27752656e-01],\n",
       "         [-1.46960616e-01,  1.87798426e-01, -1.20718196e-01,\n",
       "           6.29892945e-01,  3.59690666e-01, -6.80045068e-01,\n",
       "           1.71389014e-01, -4.41347450e-01, -9.08374786e-02,\n",
       "          -2.50980586e-01, -3.55796963e-01, -4.47571903e-01,\n",
       "          -3.13962907e-01,  6.68044806e-01, -9.35696810e-02,\n",
       "           5.29633574e-02,  6.15008809e-02, -3.23848158e-01,\n",
       "          -3.00803423e-01, -2.38040254e-01,  9.18404025e-04,\n",
       "          -8.87880698e-02,  2.06462041e-01,  2.20977843e-01]],\n",
       "\n",
       "        [[-3.96716952e-01,  3.26021194e-01,  1.03523485e-01,\n",
       "           1.16041172e+00,  1.95241094e-01, -1.35037765e-01,\n",
       "          -2.21532345e-01,  8.85631800e-01, -3.24195385e-01,\n",
       "           3.09534222e-01,  2.12985769e-01,  1.30416501e+00,\n",
       "           3.84084284e-01, -1.70919195e-01, -2.07763880e-01,\n",
       "          -3.95339541e-02,  6.70350850e-01, -2.14377627e-01,\n",
       "          -6.84429109e-02, -8.02366994e-03,  1.78315476e-01,\n",
       "          -2.31224924e-01, -9.45536122e-02, -4.34023380e-01],\n",
       "         [-3.95109802e-01,  3.29634249e-01,  1.13216870e-01,\n",
       "           1.15663433e+00,  2.05694422e-01, -1.37628943e-01,\n",
       "          -2.21984714e-01,  8.84493768e-01, -3.23704839e-01,\n",
       "           3.05032402e-01,  2.18294695e-01,  1.30023921e+00,\n",
       "           3.78371805e-01, -1.85999438e-01, -1.95265666e-01,\n",
       "          -2.94286571e-02,  6.70121193e-01, -2.19102904e-01,\n",
       "          -7.49865398e-02, -1.86299346e-03,  1.82595193e-01,\n",
       "          -2.33987778e-01, -1.00123316e-01, -4.13939327e-01],\n",
       "         [-4.00251865e-01,  3.25679004e-01,  1.11575402e-01,\n",
       "           1.16155696e+00,  1.87307626e-01, -1.35244340e-01,\n",
       "          -2.27439672e-01,  8.89946342e-01, -3.25712353e-01,\n",
       "           3.11798483e-01,  2.16912672e-01,  1.30750000e+00,\n",
       "           3.84214997e-01, -1.78269818e-01, -2.11980745e-01,\n",
       "          -4.17817123e-02,  6.68623745e-01, -2.14058593e-01,\n",
       "          -6.73028305e-02, -9.55749489e-03,  1.81727231e-01,\n",
       "          -2.22949401e-01, -9.26932171e-02, -4.28338110e-01],\n",
       "         [-3.98834199e-01,  3.27498138e-01,  1.11513317e-01,\n",
       "           1.15950322e+00,  1.95487350e-01, -1.37002185e-01,\n",
       "          -2.25138828e-01,  8.87181222e-01, -3.24738055e-01,\n",
       "           3.08707923e-01,  2.16992185e-01,  1.30466425e+00,\n",
       "           3.81710887e-01, -1.80962712e-01, -2.05383465e-01,\n",
       "          -3.70490663e-02,  6.70054436e-01, -2.14710459e-01,\n",
       "          -7.10464492e-02, -5.72911184e-03,  1.81304052e-01,\n",
       "          -2.29713410e-01, -9.57180262e-02, -4.22305882e-01],\n",
       "         [-3.89095694e-01,  3.29162031e-01,  1.06190890e-01,\n",
       "           1.15537322e+00,  2.05234960e-01, -1.36807606e-01,\n",
       "          -2.15736240e-01,  8.83207083e-01, -3.22775513e-01,\n",
       "           3.08003783e-01,  2.10491002e-01,  1.29819894e+00,\n",
       "           3.81341845e-01, -1.75950244e-01, -1.96727797e-01,\n",
       "          -3.08091659e-02,  6.73138082e-01, -2.22778857e-01,\n",
       "          -7.04287812e-02, -8.49616434e-03,  1.76839754e-01,\n",
       "          -2.39445046e-01, -9.87823084e-02, -4.26302642e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 9.60618258e-01,  4.60854828e-01, -3.22260529e-01,\n",
       "           2.56879807e-01, -6.05325639e-01, -8.41705263e-01,\n",
       "          -3.08351010e-01,  9.74444151e-02,  4.81347024e-01,\n",
       "          -1.23657966e+00,  1.59930810e-01,  2.36786380e-01,\n",
       "          -1.43861979e-01,  3.48741472e-01, -3.95861447e-01,\n",
       "           1.53804266e+00, -7.18612432e-01,  6.10444844e-01,\n",
       "          -6.18925542e-02, -1.04621733e-02, -3.40855062e-01,\n",
       "           2.92428732e-01,  3.27486694e-01,  8.75355959e-01],\n",
       "         [ 9.64984477e-01,  4.54169780e-01, -3.25347841e-01,\n",
       "           2.60779500e-01, -6.07005656e-01, -8.38750899e-01,\n",
       "          -3.04354787e-01,  9.40841436e-02,  4.83115315e-01,\n",
       "          -1.23680186e+00,  1.58157930e-01,  2.35012218e-01,\n",
       "          -1.47663340e-01,  3.44956458e-01, -4.06690329e-01,\n",
       "           1.53518450e+00, -7.15980291e-01,  6.17041230e-01,\n",
       "          -5.63503467e-02, -1.10504748e-02, -3.41363847e-01,\n",
       "           2.91316599e-01,  3.31097752e-01,  8.82762432e-01],\n",
       "         [ 9.67515826e-01,  4.56224203e-01, -3.22767377e-01,\n",
       "           2.57941514e-01, -6.06217086e-01, -8.38862360e-01,\n",
       "          -3.04956526e-01,  9.79546756e-02,  4.86206114e-01,\n",
       "          -1.23956847e+00,  1.56519815e-01,  2.35802740e-01,\n",
       "          -1.48835614e-01,  3.44750732e-01, -3.96973580e-01,\n",
       "           1.53643680e+00, -7.19721973e-01,  6.13224328e-01,\n",
       "          -5.76217324e-02, -1.39468703e-02, -3.44104826e-01,\n",
       "           2.88709462e-01,  3.28111321e-01,  8.81199121e-01],\n",
       "         [ 9.70167518e-01,  4.50199097e-01, -3.26304734e-01,\n",
       "           2.60819435e-01, -6.06593966e-01, -8.37007940e-01,\n",
       "          -3.00716192e-01,  9.43220034e-02,  4.86883909e-01,\n",
       "          -1.23798120e+00,  1.55153379e-01,  2.34512240e-01,\n",
       "          -1.51788011e-01,  3.42900515e-01, -4.05498534e-01,\n",
       "           1.53414631e+00, -7.17949212e-01,  6.18815064e-01,\n",
       "          -5.33136278e-02, -1.35919284e-02, -3.44814271e-01,\n",
       "           2.88126349e-01,  3.31596762e-01,  8.86840999e-01],\n",
       "         [ 9.67789114e-01,  4.52249616e-01, -3.25310469e-01,\n",
       "           2.59505928e-01, -6.05668485e-01, -8.38431954e-01,\n",
       "          -3.01484168e-01,  9.53511745e-02,  4.86104339e-01,\n",
       "          -1.23756635e+00,  1.55178353e-01,  2.35423952e-01,\n",
       "          -1.49941176e-01,  3.44839692e-01, -4.00686830e-01,\n",
       "           1.53532195e+00, -7.19917119e-01,  6.16078496e-01,\n",
       "          -5.62560968e-02, -1.30653298e-02, -3.44638348e-01,\n",
       "           2.88765579e-01,  3.30377758e-01,  8.83589208e-01]],\n",
       "\n",
       "        [[-3.42899531e-01,  1.23182797e+00, -6.19624615e-01,\n",
       "          -1.95946798e-01,  1.82206109e-01,  6.38049006e-01,\n",
       "          -3.23221147e-01, -2.70710111e-01, -8.74805152e-02,\n",
       "           1.29886374e-01, -6.03935421e-01,  1.93851348e-02,\n",
       "           4.17995229e-02,  2.81433254e-01, -1.74583003e-01,\n",
       "          -1.82334036e-01,  3.92008960e-01, -4.01678175e-01,\n",
       "          -1.75737098e-01, -2.16892675e-01, -5.04285157e-01,\n",
       "           3.03007931e-01, -4.11373943e-01,  1.07808605e-01],\n",
       "         [-3.39374393e-01,  1.23033071e+00, -6.09812617e-01,\n",
       "          -1.93017602e-01,  1.83220878e-01,  6.31686985e-01,\n",
       "          -3.17892462e-01, -2.57340342e-01, -9.03160274e-02,\n",
       "           1.28219202e-01, -6.11306310e-01,  3.65026947e-03,\n",
       "           4.60168310e-02,  2.95409352e-01, -1.80119306e-01,\n",
       "          -1.85906827e-01,  3.92703503e-01, -3.90670121e-01,\n",
       "          -1.71356335e-01, -2.15018764e-01, -5.16542852e-01,\n",
       "           3.02618802e-01, -4.30183947e-01,  1.20497189e-01],\n",
       "         [-3.41255516e-01,  1.22922826e+00, -6.17830753e-01,\n",
       "          -1.97163999e-01,  1.80157885e-01,  6.32450581e-01,\n",
       "          -3.21254015e-01, -2.66638458e-01, -8.48519802e-02,\n",
       "           1.25404194e-01, -6.08490646e-01,  9.12570767e-03,\n",
       "           4.52604666e-02,  2.94409871e-01, -1.80358469e-01,\n",
       "          -1.82132453e-01,  3.92655104e-01, -3.96998554e-01,\n",
       "          -1.70854717e-01, -2.15958461e-01, -5.17435491e-01,\n",
       "           3.07365030e-01, -4.19144064e-01,  1.14360884e-01],\n",
       "         [-3.39392155e-01,  1.23245335e+00, -6.14932060e-01,\n",
       "          -1.92942426e-01,  1.83971971e-01,  6.36871219e-01,\n",
       "          -3.20304155e-01, -2.62065470e-01, -9.16203260e-02,\n",
       "           1.30801916e-01, -6.08049989e-01,  1.20859900e-02,\n",
       "           4.15560007e-02,  2.86429435e-01, -1.74894720e-01,\n",
       "          -1.83831409e-01,  3.92090410e-01, -3.96973133e-01,\n",
       "          -1.74359694e-01, -2.15934202e-01, -5.08068860e-01,\n",
       "           3.01108569e-01, -4.21223313e-01,  1.15873687e-01],\n",
       "         [-3.43921214e-01,  1.23164845e+00, -6.14823222e-01,\n",
       "          -1.94940299e-01,  1.79935500e-01,  6.35706007e-01,\n",
       "          -3.22294801e-01, -2.70663619e-01, -8.66070315e-02,\n",
       "           1.30179226e-01, -6.02251112e-01,  1.58002693e-02,\n",
       "           4.85504195e-02,  2.84244239e-01, -1.78397492e-01,\n",
       "          -1.81675032e-01,  3.90596211e-01, -3.94114226e-01,\n",
       "          -1.74012870e-01, -2.16014400e-01, -5.08087039e-01,\n",
       "           3.01541209e-01, -4.16961700e-01,  1.07867301e-01]],\n",
       "\n",
       "        [[-3.35821778e-01, -2.52784878e-01, -1.23689838e-01,\n",
       "           8.92180324e-01,  5.84690087e-02, -7.41422400e-02,\n",
       "          -2.83347905e-01, -5.34661226e-02, -6.93857431e-01,\n",
       "           6.46606922e-01,  1.57760009e-01,  9.57943052e-02,\n",
       "           5.48561215e-01,  2.95405239e-01,  8.65690768e-01,\n",
       "          -2.22615868e-01,  8.61805975e-02, -3.33395213e-01,\n",
       "           2.91541368e-01, -5.15454710e-01,  3.02257240e-01,\n",
       "           2.25176543e-01,  4.01980817e-01,  2.22146362e-01],\n",
       "         [-3.35666835e-01, -2.57017851e-01, -1.19256623e-01,\n",
       "           8.87576640e-01,  5.84520400e-02, -7.37397224e-02,\n",
       "          -2.86351413e-01, -5.14771603e-02, -6.92754388e-01,\n",
       "           6.53599203e-01,  1.61767498e-01,  9.55435932e-02,\n",
       "           5.40501535e-01,  2.92939663e-01,  8.59206855e-01,\n",
       "          -2.22000584e-01,  8.87733996e-02, -3.30812842e-01,\n",
       "           2.92385757e-01, -5.17611384e-01,  3.04322362e-01,\n",
       "           2.28919864e-01,  4.03438568e-01,  2.24481612e-01],\n",
       "         [-3.39765579e-01, -2.55618244e-01, -1.28215209e-01,\n",
       "           8.95796180e-01,  5.52813634e-02, -7.39334524e-02,\n",
       "          -2.83941686e-01, -5.31909429e-02, -6.95860863e-01,\n",
       "           6.46604717e-01,  1.59373850e-01,  9.22853872e-02,\n",
       "           5.47781467e-01,  2.97553062e-01,  8.71350825e-01,\n",
       "          -2.21356884e-01,  9.35707018e-02, -3.35656524e-01,\n",
       "           2.93709993e-01, -5.12282610e-01,  2.95913160e-01,\n",
       "           2.17643887e-01,  3.94593358e-01,  2.25313589e-01],\n",
       "         [-3.37359428e-01, -2.52984822e-01, -1.32544786e-01,\n",
       "           9.00406063e-01,  5.66308871e-02, -6.92435130e-02,\n",
       "          -2.77069390e-01, -5.33655323e-02, -6.96505427e-01,\n",
       "           6.39572740e-01,  1.49120852e-01,  9.08152163e-02,\n",
       "           5.53895235e-01,  3.02409232e-01,  8.77794445e-01,\n",
       "          -2.26462558e-01,  8.83505493e-02, -3.35831791e-01,\n",
       "           2.93996960e-01, -5.09701490e-01,  2.94021457e-01,\n",
       "           2.17932835e-01,  3.88917059e-01,  2.24101156e-01],\n",
       "         [-3.38100553e-01, -2.49812707e-01, -1.23938553e-01,\n",
       "           8.98061275e-01,  5.66615760e-02, -8.08775201e-02,\n",
       "          -2.95872211e-01, -5.94381727e-02, -6.91726565e-01,\n",
       "           6.40412450e-01,  1.64684743e-01,  9.99776796e-02,\n",
       "           5.51299214e-01,  2.98398435e-01,  8.75206828e-01,\n",
       "          -2.15346694e-01,  9.71990824e-02, -3.34738523e-01,\n",
       "           2.85978884e-01, -5.10283172e-01,  2.96891630e-01,\n",
       "           2.19106391e-01,  4.06062931e-01,  2.28024140e-01]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_heads = 3\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "Q = np.random.randn(batch_size, n_heads, n, d_k).astype(np.float32)\n",
    "K = np.random.randn(batch_size, n_heads, n, d_k).astype(np.float32)\n",
    "V = np.random.randn(batch_size, n_heads, n, d_v).astype(np.float32)\n",
    "\n",
    "dot_product_attention(Q, K, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 20) (20, 20)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "\n",
    "d_model = 20\n",
    "\n",
    "Q = np.random.randn(batch_size, n, d_model)\n",
    "W_Q = np.random.randn(d_model, d_k)\n",
    "\n",
    "print(Q.shape, W_Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[Q.shape[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.02186368e+00,  4.71036170e+00,  4.78394407e-01,\n",
       "        -1.95374941e+00, -3.77729152e+00, -9.03798581e-01,\n",
       "         9.29919941e+00,  4.07358160e+00,  6.91877445e+00,\n",
       "        -1.03789112e+00, -5.33030335e+00,  2.94333103e-03,\n",
       "         8.36836844e-01, -2.43775123e+00,  1.69049897e+00,\n",
       "        -9.72307875e-01, -1.01871267e+00,  5.45488202e+00,\n",
       "        -2.25399293e+00, -1.11217924e+01],\n",
       "       [-8.12207869e-01, -4.47643595e+00, -2.39715340e+00,\n",
       "         2.19649059e+00, -7.79263434e-01,  8.36597112e-01,\n",
       "         9.88349936e-01, -1.51310167e-01, -6.97845228e+00,\n",
       "         3.78534711e-01,  3.59889430e+00, -3.08007472e+00,\n",
       "         2.68039262e+00, -1.01589415e+00, -1.61473832e+00,\n",
       "         3.14471846e+00, -5.26927758e+00, -8.46149372e+00,\n",
       "        -2.40889099e+00,  4.95341156e+00],\n",
       "       [-2.29957305e+00, -2.13494800e+00,  1.07428170e+00,\n",
       "        -6.38390754e+00,  3.69538366e+00,  4.92677788e-01,\n",
       "        -3.51141490e+00, -4.40223549e+00,  4.43084002e+00,\n",
       "         3.17779349e+00,  2.97793970e+00,  2.01123212e+00,\n",
       "        -6.37002107e-01,  1.82898085e+00,  5.37408316e-01,\n",
       "        -5.32716078e+00,  6.06644895e-02, -5.90956328e+00,\n",
       "         6.12540515e-01,  6.51270061e+00],\n",
       "       [ 5.02555212e+00,  2.44477965e+00, -2.52606181e+00,\n",
       "        -1.74178825e+00,  3.46979578e+00,  4.45915618e+00,\n",
       "         2.57818852e+00, -1.16702297e+00, -4.13418387e+00,\n",
       "         3.29267377e+00, -2.11135311e+00, -3.32745775e+00,\n",
       "         2.33346397e+00,  2.01531055e+00, -5.08009002e+00,\n",
       "         1.33973683e+00,  5.12759807e-01, -1.83234802e+00,\n",
       "         4.45385782e+00,  4.08514019e+00],\n",
       "       [ 2.58294842e+00, -6.70663159e+00,  4.31721364e+00,\n",
       "        -8.01957468e+00, -3.26245046e+00,  8.92473691e+00,\n",
       "         1.61087922e+00, -2.45511689e-01, -4.75727560e+00,\n",
       "        -2.24343444e+00,  4.64506926e+00, -1.73004983e+00,\n",
       "        -4.02476608e+00,  3.08294438e+00,  5.24827800e+00,\n",
       "        -2.72818958e+00, -4.28937858e-02, -9.94683384e+00,\n",
       "        -4.02112482e+00, -1.52041579e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(Q[0], W_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([all(np.isclose(x, y)) for x, y in zip(\n",
    "    tf.tensordot(Q, W_Q, [[len(Q.shape) - 1], [0]])[0],\n",
    "    np.dot(Q[0], W_Q))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all([all(np.isclose(x, y)) for x, y in zip(\n",
    "    tf.tensordot(Q, W_Q, [[len(Q.shape) - 1], [0]])[1],\n",
    "    np.dot(Q[1], W_Q))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_heads(x, num_heads):\n",
    "    \"\"\"xの最後の次元をnum_headsに分ける\n",
    "\n",
    "    引数:\n",
    "      x: (batch_size, N, num_heads * dim)\n",
    "    戻り値: (batch_size, num_heads, N, dim)\n",
    "    \"\"\"\n",
    "    shape = x.shape.as_list()\n",
    "    # (batch_size, N, num_heads, dim)\n",
    "    splitted = tf.reshape(\n",
    "        x, shape[:-1] + [num_heads, shape[-1] // num_heads])\n",
    "    # (batch_size, num_heads, N, dim)\n",
    "    return tf.transpose(splitted, [0, 2, 1, 3])\n",
    "\n",
    "def combine_heads(x):\n",
    "    \"\"\"xの最後の次元をnum_heads * d_vに戻す\n",
    "    \n",
    "    引数:\n",
    "      x: (batch_size, num_heads, N, d_v)\n",
    "    戻り値: (batch_size, N, num_heads * d_v)\n",
    "    \"\"\"\n",
    "    x = tf.transpose(x, [0, 2, 1, 3])\n",
    "    shape = x.shape.as_list()\n",
    "    return tf.reshape(x, shape[:-2] + [shape[-2] * shape[-1]])\n",
    "\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, d_k, d_v, **kwargs):\n",
    "        self._num_heads = num_heads\n",
    "        self._d_k = d_k\n",
    "        self._d_v = d_v\n",
    "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        Q_shape, _, _ = input_shape\n",
    "        d_model = Q_shape[-1]\n",
    "        \n",
    "        self._W_Q = self.add_weight(\n",
    "            'W_Q',\n",
    "            [d_model, self._num_heads * self._d_k],\n",
    "            initializer='glorot_uniform')\n",
    "        self._W_K = self.add_weight(\n",
    "            'W_K',\n",
    "            [d_model, self._num_heads * self._d_k],\n",
    "            initializer='glorot_uniform')\n",
    "        self._W_V = self.add_weight(\n",
    "            'W_V',\n",
    "            [d_model, self._num_heads * self._d_v],\n",
    "            initializer='glorot_uniform')\n",
    "        self._W_O = self.add_weight(\n",
    "            'W_O',\n",
    "            [self._num_heads * self._d_v, d_model],\n",
    "            initializer='glorot_uniform')\n",
    "        \n",
    "        return super(MultiHeadAttention, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        # (batch_size, N, d_model)\n",
    "        q, k, v = x\n",
    "        \n",
    "        # (batch_size, N, num_heads * d_k)\n",
    "        q_W_Q = tf.tensordot(q, self._W_Q, [[2], [0]])\n",
    "        k_W_K = tf.tensordot(k, self._W_K, [[2], [0]])\n",
    "        # (batch_size, N, num_heads * d_v)\n",
    "        v_W_V = tf.tensordot(v, self._W_V, [[2], [0]])\n",
    "        # (batch_size, num_heads, N, d_k)\n",
    "        q_W_Q = split_heads(q_W_Q, self._num_heads)\n",
    "        k_W_K = split_heads(k_W_K, self._num_heads)\n",
    "        # (batch_size, num_heads, N, d_v)\n",
    "        v_W_V = split_heads(v_W_V, self._num_heads)\n",
    "        \n",
    "        # (batch_size, num_heads, N, d_v)\n",
    "        x = dot_product_attention(q_W_Q, k_W_K, v_W_V)\n",
    "        # (batch_size, N, num_heads * d_v)\n",
    "        x = combine_heads(x)\n",
    "\n",
    "        # (batch_size, N, d_model)\n",
    "        return tf.tensordot(x, self._W_O, [[2], [0]])\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_k = 20\n",
    "d_v = 24\n",
    "d_model = 12\n",
    "n = 5\n",
    "\n",
    "inputs = [tf.keras.layers.Input(shape=(n, d_model,)) for _ in range(3)]\n",
    "multi_head_attention = MultiHeadAttention(8, d_k, d_v)(inputs)\n",
    "\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=inputs, outputs=multi_head_attention)\n",
    "model.compile(\n",
    "    optimizer=tf.train.GradientDescentOptimizer(0.001),\n",
    "    loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5, 12)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, K, V = [np.random.randn(2, n, d_model).astype(np.float32) for _ in range(3)]\n",
    "\n",
    "model.predict([Q, K, V]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeferredTensor('None', shape=(?, 1, 10, 500), dtype=float32)\n",
      "DeferredTensor('None', shape=(?, 1, 10, 500), dtype=float32)\n",
      "DeferredTensor('None', shape=(?, 1, 10, 128), dtype=float32)\n",
      "DeferredTensor('None', shape=(?, 1, 10, 128), dtype=float32)\n",
      "DeferredTensor('None', shape=(?, 1, 10, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "N = 10 # number of maximum context length\n",
    "M = 5 # number of maximum question length\n",
    "p1 = 300 # word embedding size\n",
    "C = 16 # number of maximum word length\n",
    "char_vocab_size = 1000\n",
    "p2 = 200 # character embedding size\n",
    "filter_size = 7\n",
    "num_heads = 8\n",
    "num_embedding_encoder_conv_layers = 4\n",
    "d = 128\n",
    "\n",
    "inputs = tf.keras.Input(shape=(N, p1 + p2))\n",
    "\n",
    "# (batch_size, 1, N, p1 + p2)\n",
    "x = tf.keras.layers.Reshape((1, N, p1 + p2))(inputs)\n",
    "print(x)\n",
    "\n",
    "for l in range(num_embedding_encoder_conv_layers):\n",
    "    # (batch_size, 1, N, 128)\n",
    "    print(x)\n",
    "    x = tf.keras.layers.SeparableConv2D(\n",
    "        d,\n",
    "        kernel_size=(1, 7), padding='same')(x)\n",
    "\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=inputs, outputs=x)\n",
    "model.compile(\n",
    "    optimizer=tf.train.GradientDescentOptimizer(0.001),\n",
    "    loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor2tensor.layers.common_attention import add_timing_signal_1d\n",
    "\n",
    "class PositionEncoding(tf.keras.layers.Lambda):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PositionEncoding, self).__init__(\n",
    "            function=lambda x: add_timing_signal_1d(x),\n",
    "            **kwargs)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "inputs = tf.keras.Input(shape=(N, p1 + p2))\n",
    "x = PositionEncoding()(inputs)\n",
    "# (batch_size, 1, N, p1 + p2)\n",
    "x = tf.keras.layers.Reshape((1, N, p1 + p2))(x)\n",
    "\n",
    "for l in range(num_embedding_encoder_conv_layers):\n",
    "    # (batch_size, 1, N, d)\n",
    "    x = tf.keras.layers.SeparableConv2D(\n",
    "        d,\n",
    "        kernel_size=(1, 7),\n",
    "        padding='same')(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "# (batch_size, N, d)\n",
    "x = tf.keras.layers.Reshape((N, -1))(x)\n",
    "# (batch_size, N, d)\n",
    "x = MultiHeadAttention(num_heads, d, d)([x] * 3)\n",
    "# (batch_size, N, d)\n",
    "x = tf.keras.layers.Dense(d)(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "model = tf.keras.models.Model(\n",
    "    inputs=inputs, outputs=x)\n",
    "model.compile(\n",
    "    optimizer=tf.train.GradientDescentOptimizer(0.001),\n",
    "    loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 128)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.random.randn(batch_size, N, p1 + p2)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一応出来たけど不安…少なくともdropoutは後で追加する、後layer normalization、layer dropout\n",
    "\n",
    "NLPLearn/QANetだとmultihead attentionに畳込みを使っているのが気になる。\n",
    "QANetにもTransformerにも元論文にそんな記述は見つけていない。\n",
    "\n",
    "ただし、transformerには畳込みの実装もある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
