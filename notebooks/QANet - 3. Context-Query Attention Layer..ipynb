{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly()\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "batch_size = 2\n",
    "N = 10 # number of maximum context length\n",
    "M = 5 # number of maximum question length\n",
    "d = 128\n",
    "\n",
    "context = np.random.randn(batch_size, N, d)\n",
    "query = np.random.randn(batch_size, M, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from BiDAF\n",
    "\n",
    "> α(h, u) = w⊤ [h; u; h ◦ (S)\n",
    "u], where w(S) ∈ R6d is a trainable weight vector, ◦ is elementwise multiplication, [; ] is vector concatenation across row, and implicit multiplication is matrix multiplication\n",
    "\n",
    "tri_linear: https://github.com/allenai/bi-att-flow/blob/master/my/tensorflow/nn.py#L125\n",
    "\n",
    "### Context-Query Attention\n",
    "\n",
    "> We use C and Q to denote the encoded context and query. The context-to-query attention is constructed as follows: We first computer the similarities between each pair of context and query words, rendering a similarity matrix S ∈ Rn×m. We then normalize each row of S by applying the softmax function, getting a matrixS.Thenthecontext-to-queryattentioniscomputedasA=S·QT ∈Rn×d.Thesimilarity function used here is the trilinear function (Seo et al., 2016):\n",
    "f(q, c) = W0[q, c, q ⊙ c],\n",
    "where ⊙ is the element-wise multiplication and W0 is a trainable variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMaxtirx(tf.keras.layers.Layer):\n",
    "    \"\"\"contexとqueryのconfusion matrixを計算する\n",
    "    \n",
    "    Input:\n",
    "      context: (batch_size, N, dim)\n",
    "      query: (batch_size, M, dim)\n",
    "      context_mask: (batch_size, N)\n",
    "      query_mask: (batch_size, M)\n",
    "      \n",
    "    Output: (batch_size, N, M)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, initializer='glorot_uniform', **kwargs):\n",
    "        self._initializer = initializer\n",
    "        super(ConfusionMaxtirx, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        c_shape, _, _, _ = input_shape\n",
    "        \n",
    "        self._W = self.add_weight(\n",
    "            'weight',\n",
    "            [c_shape[-1] * 3, 1],\n",
    "            initializer=self._initializer)\n",
    "        \n",
    "        super(ConfusionMaxtirx, self).build(input_shape)\n",
    "    def call(self, x):\n",
    "        c, q, c_mask, q_mask = x\n",
    "        N, M, d = c.shape[1], q.shape[1], c.shape[-1]\n",
    "        \n",
    "        # (batch_size, N, M, d)\n",
    "        c = tf.tile(tf.expand_dims(c, 2), [1, 1, M, 1])\n",
    "        q = tf.tile(tf.expand_dims(q, 1), [1, N, 1, 1])\n",
    "        # (batch_size, N * M, d)\n",
    "        c = tf.reshape(c, [-1, N * M, d])\n",
    "        q = tf.reshape(q, [-1, N * M, d])\n",
    "        c_q = c * q\n",
    "        # (batch_size, N * M, d * 3)\n",
    "        S = tf.concat([c, q, c_q], 2)\n",
    "        # (batch_size, N, M)\n",
    "        logits = tf.reshape(tf.tensordot(S, self._W, [[2], [0]]), [-1, N, M])\n",
    "        \n",
    "        # (batch_size, N, M)\n",
    "        c_mask = tf.cast(tf.tile(tf.expand_dims(c_mask, 2), [1, 1, M]), tf.bool)\n",
    "        q_mask = tf.cast(tf.tile(tf.expand_dims(q_mask, 1), [1, N, 1]), tf.bool)\n",
    "        \n",
    "        return exp_mask(logits, c_mask & q_mask)\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        c_shape, q_shape, _, _ = input_shape\n",
    "        return tf.TensorShape([\n",
    "            c_shape[0], c_shape[1], q_shape[1]])\n",
    "\n",
    "VERY_NEGATIVE_NUMBER = - 1e30\n",
    "    \n",
    "def exp_mask(val, mask):\n",
    "    return val + (1. - tf.cast(mask, tf.float32)) * VERY_NEGATIVE_NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [False False False False False]\n",
      "  [False False False False False]]\n",
      "\n",
      " [[ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [False False False False False]\n",
      "  [False False False False False]]], shape=(2, 10, 5), dtype=bool)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=935, shape=(2, 10, 5), dtype=float32, numpy=\n",
       "array([[[-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-1.e+30, -1.e+30, -1.e+30, -1.e+30, -1.e+30],\n",
       "        [-1.e+30, -1.e+30, -1.e+30, -1.e+30, -1.e+30]],\n",
       "\n",
       "       [[-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-0.e+00, -0.e+00, -0.e+00, -0.e+00, -1.e+30],\n",
       "        [-1.e+30, -1.e+30, -1.e+30, -1.e+30, -1.e+30],\n",
       "        [-1.e+30, -1.e+30, -1.e+30, -1.e+30, -1.e+30]]], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_c = np.random.randn(2, 10, 128)\n",
    "_q = np.random.randn(2, 5, 128)\n",
    "_c_mask = np.array([[1.] * 8 + [0.] * 2] * 2)\n",
    "_q_mask = np.array([[1.] * 4 + [0.] * 1] * 2)\n",
    "\n",
    "__c_mask = tf.cast(tf.tile(tf.expand_dims(_c_mask, 2), [1, 1, 5]), tf.bool)\n",
    "__q_mask = tf.cast(tf.tile(tf.expand_dims(_q_mask, 1), [1, 10, 1]), tf.bool)\n",
    "print(__c_mask & __q_mask)\n",
    "__cq_mask = __c_mask & __q_mask\n",
    "\n",
    "(1. - tf.cast(__cq_mask, tf.float32)) * (- 1e30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "from unittest import TestCase\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "class SimilarityMaxrixTest(TestCase):\n",
    "    def test_similarity_matrix(self):\n",
    "        in_context = tf.keras.layers.Input(shape=(10, 128))\n",
    "        in_query = tf.keras.layers.Input(shape=(5, 128))\n",
    "        in_context_mask = tf.keras.layers.Input(shape=(10,))\n",
    "        in_query_mask = tf.keras.layers.Input(shape=(5,))\n",
    "\n",
    "        S = ConfusionMaxtirx(\n",
    "            initializer=tf.keras.initializers.Ones()\n",
    "        )([in_context, in_query, in_context_mask, in_query_mask])\n",
    "\n",
    "        model = tf.keras.models.Model(\n",
    "            inputs=[in_context, in_query,\n",
    "                   in_context_mask, in_query_mask], outputs=S)\n",
    "        model.compile(\n",
    "            optimizer=tf.train.GradientDescentOptimizer(0.001),\n",
    "            loss='mse')\n",
    "        \n",
    "        context = np.random.randn(2, 10, 128)\n",
    "        query = np.random.randn(2, 5, 128)\n",
    "        context_mask = np.array([[1.] * 8 + [0.] * 2] * 2)\n",
    "        query_mask = np.array([[1.] * 4 + [0.] * 1] * 2)\n",
    "        prediction = model.predict([context, query, context_mask, query_mask])\n",
    "        \n",
    "        c_ = context[0]\n",
    "        q_ = query[0]\n",
    "        \n",
    "        print(prediction)\n",
    "\n",
    "        self.assertTrue(np.isclose(\n",
    "            sum(np.sum(x) for x in [c_[0], q_[0], c_[0] * q_[0]]),\n",
    "            prediction[0][0][0]))\n",
    "        self.assertTrue(np.isclose(\n",
    "            sum(np.sum(x) for x in [c_[0], q_[1], c_[0] * q_[1]]),\n",
    "            prediction[0][0][1]))\n",
    "        self.assertTrue(np.isclose(\n",
    "            sum(np.sum(x) for x in [c_[0], q_[2], c_[0] * q_[2]]),\n",
    "            prediction[0][0][2]))\n",
    "\n",
    "        self.assertTrue(np.isclose(\n",
    "            sum(np.sum(x) for x in [c_[1], q_[0], c_[1] * q_[0]]),\n",
    "            prediction[0][1][0]))\n",
    "        self.assertTrue(np.isclose(\n",
    "            sum(np.sum(x) for x in [c_[1], q_[1], c_[1] * q_[1]]),\n",
    "            prediction[0][1][1]))\n",
    "        self.assertTrue(np.isclose(\n",
    "            sum(np.sum(x) for x in [c_[1], q_[2], c_[1] * q_[2]]),\n",
    "            prediction[0][1][2]))\n",
    "        \n",
    "        self.assertTrue((prediction[0][8] < -1e29).all())\n",
    "        self.assertTrue((prediction[0][9] < -1e29).all())\n",
    "\n",
    "        self.assertTrue((prediction[0][:, 4] < -1e29).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_inspect.py:55: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-26.680727     8.706963     4.0591383    1.026109    20.791464  ]\n",
      "  [  8.203361    26.703358    10.090115    28.830126     4.4024324 ]\n",
      "  [ -0.2873788   22.457983    39.042847    35.48367     17.648518  ]\n",
      "  [-19.38573    -25.331831   -18.605465    -4.207034    -8.938112  ]\n",
      "  [ -7.7391853    8.7559395   29.606297    23.942646    -5.004421  ]\n",
      "  [ -8.550956    13.350004     5.2746067    1.4550667   -5.768668  ]\n",
      "  [-19.972979    -9.359817   -22.498337    11.988964    16.971111  ]\n",
      "  [ -9.590694    -0.09886384  -7.1513443  -16.830381   -17.28229   ]\n",
      "  [ -6.801503     2.1188016    9.362334    -0.9295566   -4.843854  ]\n",
      "  [  4.9242787    8.273638    -4.1670313   24.31109     -6.914058  ]]\n",
      "\n",
      " [[-10.826447    21.88923      2.2997658   12.595575    13.492126  ]\n",
      "  [ 11.372191     0.44924843   6.1759567   13.439011   -23.922638  ]\n",
      "  [  2.4858618   11.282563     3.6231716   21.716213     3.372271  ]\n",
      "  [-42.06301    -19.71345     20.213993     8.019485   -14.077389  ]\n",
      "  [  8.271914   -21.845125     7.9684987   15.512133    15.479257  ]\n",
      "  [  1.2354183    5.5835905   11.967703     7.7973695    2.0094347 ]\n",
      "  [ -7.371462   -14.783776    11.089916     8.275202    -7.1816077 ]\n",
      "  [-14.493207    12.04567      5.1173925   31.715414    -2.1447353 ]\n",
      "  [ 20.024584     4.664087    13.83026     48.843414     7.4453564 ]\n",
      "  [ 12.938434     2.6900573    9.480387    31.189266    15.918323  ]]], shape=(2, 10, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [False False False False False]\n",
      "  [False False False False False]]\n",
      "\n",
      " [[ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [ True  True  True  True  True]\n",
      "  [False False False False False]\n",
      "  [False False False False False]]], shape=(2, 10, 5), dtype=bool)\n",
      "tf.Tensor(\n",
      "[[[ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]]\n",
      "\n",
      " [[ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]\n",
      "  [ True  True  True  True False]]], shape=(2, 10, 5), dtype=bool)\n",
      "[[[-2.6680727e+01  8.7069626e+00  4.0591383e+00  1.0261090e+00\n",
      "   -1.0000000e+30]\n",
      "  [ 8.2033606e+00  2.6703358e+01  1.0090115e+01  2.8830126e+01\n",
      "   -1.0000000e+30]\n",
      "  [-2.8737879e-01  2.2457983e+01  3.9042847e+01  3.5483669e+01\n",
      "   -1.0000000e+30]\n",
      "  [-1.9385731e+01 -2.5331831e+01 -1.8605465e+01 -4.2070341e+00\n",
      "   -1.0000000e+30]\n",
      "  [-7.7391853e+00  8.7559395e+00  2.9606297e+01  2.3942646e+01\n",
      "   -1.0000000e+30]\n",
      "  [-8.5509558e+00  1.3350004e+01  5.2746067e+00  1.4550667e+00\n",
      "   -1.0000000e+30]\n",
      "  [-1.9972979e+01 -9.3598166e+00 -2.2498337e+01  1.1988964e+01\n",
      "   -1.0000000e+30]\n",
      "  [-9.5906944e+00 -9.8863840e-02 -7.1513443e+00 -1.6830381e+01\n",
      "   -1.0000000e+30]\n",
      "  [-1.0000000e+30 -1.0000000e+30 -1.0000000e+30 -1.0000000e+30\n",
      "   -1.0000000e+30]\n",
      "  [-1.0000000e+30 -1.0000000e+30 -1.0000000e+30 -1.0000000e+30\n",
      "   -1.0000000e+30]]\n",
      "\n",
      " [[-1.0826447e+01  2.1889231e+01  2.2997658e+00  1.2595575e+01\n",
      "   -1.0000000e+30]\n",
      "  [ 1.1372191e+01  4.4924843e-01  6.1759567e+00  1.3439011e+01\n",
      "   -1.0000000e+30]\n",
      "  [ 2.4858618e+00  1.1282563e+01  3.6231716e+00  2.1716213e+01\n",
      "   -1.0000000e+30]\n",
      "  [-4.2063011e+01 -1.9713449e+01  2.0213993e+01  8.0194855e+00\n",
      "   -1.0000000e+30]\n",
      "  [ 8.2719135e+00 -2.1845125e+01  7.9684987e+00  1.5512133e+01\n",
      "   -1.0000000e+30]\n",
      "  [ 1.2354183e+00  5.5835905e+00  1.1967703e+01  7.7973695e+00\n",
      "   -1.0000000e+30]\n",
      "  [-7.3714619e+00 -1.4783776e+01  1.1089916e+01  8.2752018e+00\n",
      "   -1.0000000e+30]\n",
      "  [-1.4493207e+01  1.2045670e+01  5.1173925e+00  3.1715414e+01\n",
      "   -1.0000000e+30]\n",
      "  [-1.0000000e+30 -1.0000000e+30 -1.0000000e+30 -1.0000000e+30\n",
      "   -1.0000000e+30]\n",
      "  [-1.0000000e+30 -1.0000000e+30 -1.0000000e+30 -1.0000000e+30\n",
      "   -1.0000000e+30]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f946c2eddd8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(tf.keras)\n",
    "\n",
    "class ContextQueryAttention(tf.keras.layers.Lambda):\n",
    "    def __init__(self, **kwargs):\n",
    "        def fn(x):\n",
    "            \"\"\"context-to-query attention\n",
    "            \n",
    "              引数:\n",
    "                x:\n",
    "                  S_: (batch_size, N, M)\n",
    "                    similarity-matrixを行方向にsoftmaxしたもの\n",
    "                  q: (batch_size, M, d)\n",
    "            \"\"\"\n",
    "            S_, q = x\n",
    "            return tf.matmul(S_, q)\n",
    "            \n",
    "        super(ContextQueryAttention, self).__init__(\n",
    "            function=fn, **kwargs)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        d = input_shape[1][-1]\n",
    "        N = input_shape[0][1]\n",
    "        return tf.TensorShape([input_shape[0][0], N, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryContextAttention(tf.keras.layers.Lambda):\n",
    "    def __init__(self, **kwargs):\n",
    "        def fn(x):\n",
    "            \"\"\"query-to-context attention\n",
    "            \n",
    "              引数:\n",
    "                x:\n",
    "                  S_: (batch_size, N, M)\n",
    "                    similarity-matrixを行方向にsoftmaxしたもの\n",
    "                  S__: (batch_size, N, M)\n",
    "                    similarity-matrixを列方向にsoftmaxしたもの\n",
    "                  c: (batch_size, N, d)\n",
    "            \"\"\"\n",
    "            S_, S__, c = x\n",
    "            return tf.matmul(tf.matmul(S_, S__, transpose_b=True), c)\n",
    "        \n",
    "        super(QueryContextAttention, self).__init__(\n",
    "            function=fn, **kwargs)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        d = input_shape[2][-1]\n",
    "        N = input_shape[0][1]\n",
    "        return tf.TensorShape([input_shape[0][0], N, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:All custom layers should implement the `compute_output_shape` method. This layer (lambda_15) is relying on the base `Layer.compute_output_shape` implementation, which will start raising a `NotImplementedError` as of July 1st, 2018.\n",
      "WARNING:tensorflow:All custom layers should implement the `compute_output_shape` method. This layer (lambda_16) is relying on the base `Layer.compute_output_shape` implementation, which will start raising a `NotImplementedError` as of July 1st, 2018.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[[ 0.42624378, -0.42186388, -0.3423511 , ...,  0.4141646 ,\n",
       "           0.2401321 , -0.20993373],\n",
       "         [ 0.286063  , -0.3810072 , -0.675566  , ...,  0.5241299 ,\n",
       "           0.3081832 , -0.2659616 ],\n",
       "         [ 0.3023329 , -0.25960472, -0.5013888 , ...,  0.8884078 ,\n",
       "           0.0510106 ,  0.09299337],\n",
       "         ...,\n",
       "         [ 0.39595932, -0.34718075, -0.7454579 , ...,  0.6564402 ,\n",
       "          -0.49691024, -0.253864  ],\n",
       "         [ 0.3028922 , -0.25585917, -0.49765366, ...,  0.90051794,\n",
       "           0.04516283,  0.10472202],\n",
       "         [ 0.27646336, -0.38716143, -0.6815043 , ...,  0.5068797 ,\n",
       "           0.39329955, -0.27373126]],\n",
       " \n",
       "        [[ 0.19743341, -0.40965334, -0.68006325, ..., -0.32033688,\n",
       "           0.6024212 , -0.33785802],\n",
       "         [ 0.47385624, -0.6860708 , -0.86413115, ..., -0.41086742,\n",
       "           1.0548424 , -0.06912111],\n",
       "         [ 0.5347344 , -0.760919  , -0.89348876, ..., -0.40699884,\n",
       "           1.1184912 , -0.06335605],\n",
       "         ...,\n",
       "         [ 0.5347473 , -0.76093197, -0.8934966 , ..., -0.40699837,\n",
       "           1.1185097 , -0.06335102],\n",
       "         [ 0.5347473 , -0.76093197, -0.8934966 , ..., -0.40699837,\n",
       "           1.1185097 , -0.06335102],\n",
       "         [ 0.5347472 , -0.76093173, -0.8934964 , ..., -0.4069984 ,\n",
       "           1.1185094 , -0.06335097]]], dtype=float32),\n",
       " array([[[ 0.42275268, -1.0989937 ,  1.3531677 , ...,  0.32436863,\n",
       "          -0.37283337, -0.30638686],\n",
       "         [-0.6760748 ,  0.5671565 , -0.42508534, ..., -0.08006503,\n",
       "           1.654296  , -0.43266737],\n",
       "         [-0.83858985,  0.5539939 , -0.5040673 , ..., -0.10457284,\n",
       "           1.8501644 , -0.3333049 ],\n",
       "         ...,\n",
       "         [ 0.67113477,  0.67675835,  0.22842   , ...,  0.12331497,\n",
       "           0.03141527, -1.2549692 ],\n",
       "         [-0.83755916,  0.55407816, -0.5035706 , ..., -0.10441636,\n",
       "           1.8489251 , -0.33392882],\n",
       "         [-0.83684766,  0.5540765 , -0.5030726 , ..., -0.1043357 ,\n",
       "           1.847966  , -0.3345355 ]],\n",
       " \n",
       "        [[-0.21092707, -0.35788223,  0.9595733 , ...,  0.12747711,\n",
       "           0.5175401 ,  0.7480438 ],\n",
       "         [-1.1791903 , -0.29241985, -1.937903  , ...,  1.7928066 ,\n",
       "           1.3780998 ,  2.0491726 ],\n",
       "         [-1.1805468 , -0.29091486, -1.9392016 , ...,  1.7929391 ,\n",
       "           1.3790992 ,  2.0498788 ],\n",
       "         ...,\n",
       "         [-1.1805753 , -0.29091287, -1.939287  , ...,  1.7929881 ,\n",
       "           1.3791246 ,  2.0499172 ],\n",
       "         [-1.1805753 , -0.29091287, -1.939287  , ...,  1.7929881 ,\n",
       "           1.3791246 ,  2.0499172 ],\n",
       "         [-1.1805749 , -0.2909129 , -1.9392865 , ...,  1.7929877 ,\n",
       "           1.3791244 ,  2.0499172 ]]], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_context = tf.keras.layers.Input(shape=(10, 128))\n",
    "in_query = tf.keras.layers.Input(shape=(5, 128))\n",
    "\n",
    "S = SimilarityMaxtirx(initializer=tf.keras.initializers.Ones())([in_context, in_query])\n",
    "S_ = tf.keras.layers.Lambda(lambda x: tf.nn.softmax(x, 2))(S)\n",
    "S__ = tf.keras.layers.Lambda(lambda x: tf.nn.softmax(x, 1))(S)\n",
    "A = ContextQueryAttention()([S_, in_query])\n",
    "B = QueryContextAttention()([S_, S__, in_context])\n",
    "\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[in_context, in_query], outputs=[A, B])\n",
    "model.compile(\n",
    "    optimizer=tf.train.GradientDescentOptimizer(0.001),\n",
    "    loss='mse')\n",
    "prediction = model.predict([context, query])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10, 128)\n",
      "(2, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "print(prediction[0].shape)\n",
    "print(prediction[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3まで終わった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
